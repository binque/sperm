* hbase
** View
*** 业强 2012-08-16 hbase讲座
file:./images/hbase-architecture.png


HRegion类似于tablet，每个HRegion有很多Store存储不同的column family。

对于memstore内存大小限制的话，有两个方面：
   - HRegion如果总体内存比较大的话，那么会选择几个Store里面的memstore进行flush
   - 如果Store里面的memstore本身比较大的话，也会进行flush

scan过程大致是这样的：
   - 首先scanner得到memstore以及所有的hfile，以及这个似乎时候的timestamp（hbase使用timestamp作为version)进行归并排序。
   - 如果期间memstore发生写，或者是flush，或者是进行compaction的话，那么会通知scanner
   - scanner会重新组织这些内容，根据上次读取到的value,忽路duplicated的数据。   
这样的好处就是通常在scanner的时候不会阻塞其他操作。

--------------------

但是我看了一下leveldb代码，觉得实现上更好。对于immutable memtable以及memtable做引用计数，在iterator里面保存两个table。
如果memtable compaction之后的话，那么直接创建一个新的memtable即可。原有的table在iterator销毁的时候就会自动释放。

--------------------

对于column family是可以设置超时时间的。在进行flush或者是compaction的时候，会判断这个value是否超过ttl。如果超过ttl的话那么就会直接丢弃。

*** asynchbase
https://github.com/stumbleupon/asynchbase

   - asynchbase和HTable的性能对比 http://www.tsunanet.net/~tsuna/asynchbase/benchmark/viz.html 
   - OpenTSDB is a distributed, scalable Time Series Database (TSDB)  http://opentsdb.net/index.html 

从看asynchbase介绍来看，我猜想asynchbase用在MR范围还是有限的。
   - asynchbase就是一个异步client，能够很好地解决一个app里面对于hbase有很多个连接的场景。
   - 但是在MR里面，拿我们现在的HourlyProcedure来说，每次get都是一个同步过程，一定要取回结果才能够进行下一步的操作。整个MR框架就限制了异步client的作用。
   - asynchbase现在使用的场景应该是OpenTSDB，因为没有MR框架限制，所以异步client可以工作很好。

*** HBase Write Path
http://www.cloudera.com/blog/2012/06/hbase-write-path/

At first, it locates the address of the region server hosting the -ROOT- region from the ZooKeeper quorum.  From the root region server, the client finds out the location of the region server hosting the -META- region.（首先从Zookeeper里面找到-ROOT- region所在的region server，然后在找到对应的-META- region所在的region server，最后找到数据所在的region server。 *TODO（dirlt）：问题是-ROOT-和-META-里面是怎么组织数据的呢，怎么来帮助定位的？* ）

写入的Write Ahead Log存放在/hbase/.logs下面，文件路径是 /hbase/.logs/<host>,<port>,<startcode>，文件名称/hbase/.logs/<host>,<port>,<startcode>/<host>%2C<port>%2C<startcode>.<timestamp>
#+BEGIN_EXAMPLE
/hbase/.logs/srv.example.com,60020,1254173957298
/hbase/.logs/srv.example.com,60020,1254173957298/srv.example.com%2C60020%2C125417395
#+END_EXAMPLE

** Usage
*** hbase shell
   - scan 'test'
   - scan 'test' , { LIMIT=>10 }
   - scan 'test' , { COLUMN=>['cf:url'] }
   - scan 'test' , { STARTROW=>'xyz' }
   - count 'test'
   - create 'test', { NAME=>'cf' }
   - get 'test', {COLUMN = > ['cf:url']}

*** hbase increment
http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Increment.html

*** hbase join
http://stackoverflow.com/questions/11327316/how-to-join-tables-in-hbase

其实对于join来说无非三种：
   - sort join 两路排序，之后进行merge。
   - loop join 没有任何排序，直接循环匹配。
   - hash join 遍历一路的时候去查另外一路。

对于MR来说，个人认为sort join通常是效率最高的方式，而hash join次之（hbase的read效率不是很高）。

*** hbase的kv大小限制
下面代码可以进行检测
#+BEGIN_SRC Java
package com.umeng.dp.helper;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.HColumnDescriptor;
import org.apache.hadoop.hbase.HTableDescriptor;
import org.apache.hadoop.hbase.client.HBaseAdmin;
import org.apache.hadoop.hbase.client.HTable;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.util.Bytes;

// dirlt: we should know what's the max size of hbase value.
// turns out max size is 10M. 
// refers to the HTable::validatePut this method.
public class TestMaxSizeOfHBaseValue {
    private final static byte[] kByteColumnFamily = Bytes.toBytes("CF");
    private final static byte[] kByteColumn = Bytes.toBytes("CL");
    private final static String kTableName = "test.temporary";

    private Configuration conf_ = null;

    public TestMaxSizeOfHBaseValue(Configuration conf) {
        conf_ = conf;
    }

    public void run() throws IOException {
        HBaseAdmin admin = new HBaseAdmin(conf_);
        if (admin.isTableAvailable(kTableName)) {
            admin.disableTable(kTableName);
            admin.deleteTable(kTableName);
        }
        HTableDescriptor dp = new HTableDescriptor(kTableName);
        dp.addFamily(new HColumnDescriptor(kByteColumnFamily));
        admin.createTable(dp);
        HTable table = new HTable(kTableName);
        int size = 2048;
        while(true){
            byte[] value = new byte[size-1];
            Put put = new Put(Bytes.toBytes("row"));
            put.add(kByteColumnFamily, kByteColumn, value);
            try {
                table.put(put);
            }catch(IllegalArgumentException e) {
                e.printStackTrace();
                break;
            }
            System.out.println("value size = "+ size +", succeed");
            if(size >= 8 * 1024 * 1024) {
                break;
            }
            size *= 2;
        }
        table.close();
        admin.disableTable(kTableName);
        admin.deleteTable(kTableName);
    }
    
    public static void main(String[] args) throws IOException {
        Configuration conf = HBaseConfiguration.create();
        TestMaxSizeOfHBaseValue test = new TestMaxSizeOfHBaseValue(conf);
        test.run();
    }
}
#+END_SRC
对于默认配置的集群是8M。其实跟进table.put这个方法的话，可以发现实际上在validatePut这里进行了验证。

#+BEGIN_SRC Java
  // validate for well-formedness
  private void validatePut(final Put put) throws IllegalArgumentException{
    if (put.isEmpty()) {
      throw new IllegalArgumentException("No columns to insert");
    }
    if (maxKeyValueSize > 0) {
      for (List<KeyValue> list : put.getFamilyMap().values()) {
        for (KeyValue kv : list) {
          if (kv.getLength() > maxKeyValueSize) {
            throw new IllegalArgumentException("KeyValue size too large");
          }
        }
      }
    }
  }
#+END_SRC

这里maxKeyValueSize是从配置文件里面读取出来的。
#+BEGIN_SRC Java
this.maxKeyValueSize = conf.getInt("hbase.client.keyvalue.maxsize", -1);
#+END_SRC
因此可以修改hbase.client.keyvalue.maxsize来修改大小。从名字上看这个大小应该是在client端进行限制的，个人推测在server端应该是没有大小限制的。

*** create table API
#+BEGIN_SRC Java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.HTableDescriptor;
import org.apache.hadoop.hbase.HColumnDescriptor;
import org.apache.hadoop.hbase.client.HBaseAdmin;
import org.apache.hadoop.hbase.client.Get;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.HTable;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.util.Bytes;
import java.util.Date;

public class App  {
  public static void main( String[] args ) throws java.io.IOException {
    Configuration conf=HBaseConfiguration.create();
    // create table.
    HBaseAdmin hbase=new HBaseAdmin(conf);
    HTableDescriptor desc=new HTableDescriptor("TEST");
    desc.addFamily(new HColumnDescriptor(Bytes.toBytes("personal")));
    desc.addFamily(new HColumnDescriptor(Bytes.toBytes("account")));
    hbase.createTable(desc);
  }
}
#+END_SRC

*** use python
使用python来访问hbase确实可以很大地提高开发效率，但是通过thrift server来进行中转的话对于性能还是存在影响的，因此比较适合测试。
   - 首先需要启动thrift server。hbase-deamon.sh start thrift
   - 然后安装happybase。pip install happybase github: https://github.com/wbolster/happybase doc: http://happybase.readthedocs.org/en/latest/index.html
使用起来还是比较简单的，documentation里面的说明也非常详细。

#+BEGIN_SRC Python
#!/usr/bin/env python
#coding:utf-8
#Copyright (C) dirlt

import happybase

# create connection.
connection = happybase.Connection('localhost', autoconnect = False)
connection.open()

# create table.
kTableName = 'for-test'
kColumnFamily = 'cf'

if(kTableName in connection.tables()):
    connection.disable_table('for-test')
    connection.delete_table('for-test')
connection.create_table(kTableName, {kColumnFamily:{}})
table = connection.table(kTableName)

# put data.
table.put('row1', {kColumnFamily+':c1':'value1'})

# get data.
row = table.row('row1')
assert(row[kColumnFamily + ':c1'] == 'value1')
#+END_SRC

--------------------
*NOTE（dirlt）：发现还是存在一些不兼容的thrift协议，比如使用scan似乎就存在问题*

#+BEGIN_SRC Python
#!/usr/bin/env python
#coding:utf-8
#Copyright (C) dirlt

import happybase

# create connection.
connection = happybase.Connection('localhost', autoconnect = False)
connection.open()

print connection.tables()

table = connection.table('for-test')
iters = table.scan()

for k,v in iters:
    print k,v

#+END_SRC

出现了下面这些问题：
#+BEGIN_EXAMPLE
Traceback (most recent call last):
  File "./hbase.py", line 20, in <module>
    for k,v in iters:
  File "/usr/local/lib/python2.7/dist-packages/happybase/api.py", line 567, in scan
    scan_id = client.scannerOpenWithScan(self.name, scan)
  File "/usr/local/lib/python2.7/dist-packages/happybase/hbase/Hbase.py", line 1716, in scannerOpenWithScan
    return self.recv_scannerOpenWithScan()
  File "/usr/local/lib/python2.7/dist-packages/happybase/hbase/Hbase.py", line 1733, in recv_scannerOpenWithScan
    raise x
thrift.Thrift.TApplicationException: Invalid method name: 'scannerOpenWithScan'
#+END_EXAMPLE



