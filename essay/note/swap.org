* swap
** ozzie
今天粗看了一下oozie的一些内容，下面这些链接可以很容易地baidu到
   - http://www.infoq.com/cn/articles/introductionOozie oozie简介
   - http://incubator.apache.org/oozie/overview.html oozie overview
   - http://incubator.apache.org/oozie/map-reduce-cookbook.html oozie简单地跑一个mapreduce
   - http://incubator.apache.org/oozie/docs/3.2.0-incubating/docs/index.html oozie文档
     - workflow http://incubator.apache.org/oozie/docs/3.2.0-incubating/docs/WorkflowFunctionalSpec.html
     - coordinator http://incubator.apache.org/oozie/docs/3.2.0-incubating/docs/CoordinatorFunctionalSpec.html
     - bundle http://incubator.apache.org/oozie/docs/3.2.0-incubating/docs/BundleFunctionalSpec.html

oozie工作方式也是启动一个mapper任务放在cluster上面运行。大致上来看的话需要三个文件：
   - workflow.xml ozzie读取它来知道每个任务DAG如何并且失败以及成功之后如何处理。
   - job.properties 这个用来存放一些任务相关的参数等。这个部分其实可以和workflow.xml放在一起，但是分离出来的话可以方便分离。
   - lib 目录下面存放启动启动需要的库文件比如jar或者是so等。
然后我们需要将这写文件提交到hdfs上面，然后使用ozzie启动。ozzie会提供一个回调url，启动的任务应该会定时向这些url进行汇报状态（回调），或者是
ozzie去查询这些任务状态（这些任务应该也会内置httpserver）。总地来说oozie执行分为三种模式：
   - workflow. 这种方式非常简单，就是定义DAG来执行。
   - coordinator. workflow缺点非常明显，就是没有办法定时触发或者是条件触发。coordinator可以完成这个需求。coordinator构建在workflow工作方式上面，可以定时运行也可以触发运行。
触发条件非常巧妙，提供一个叫做synchronous dataset的数据集。这个数据集其实就是一个url，不过这个url通过时间来进行区分。比如hdfs://foo:9000/usr/logs/2009/04/15/23/30.
   - bundle. bundle的作用就是将多个coordinator管理起来。这样我们只需要提供一个bundle提交即可。然后可以start/stop/suspend/resume任何coordinator.

** java
   - 日志,log4j
   - 泛型 
   - 容器 
   - 多线程

