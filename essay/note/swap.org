* swap
#+TITLE:     swap
#+AUTHOR:    dirtysalt
#+EMAIL:     dirtysalt1987@gmail.com
#+DESCRIPTION:
#+KEYWORDS:
#+LANGUAGE:  en
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:{} -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:   
#+LINK_HOME: 
#+XSLT:

** 2012Q3 OKR
1、参与线上线下统计分析逻辑整合和后端改造工作 30%
2、数据平台调度器的设计实现和上线，满足目前的需求 30%
3、统计分析3.0设计和实现 20%
4、数据平台数据流改造，kafka直接写入hdfs 10%
5、hadoop/hbase加深了解 10%

** ozzie
   - http://incubator.apache.org/oozie/overview.html
   - http://incubator.apache.org/oozie/map-reduce-cookbook.html
ozzie将每一个工作流作为一个task来进行提交。配置看上去还好，给出了如何从原来hadoop提交方式切换到提交oozie的方式。大致上来看的话需要三个文件：
   - workflow.xml ozzie读取它来知道每个任务DAG如何并且失败以及成功之后如何处理。
   - job.properties 这个用来存放一些任务相关的参数等。这个部分其实可以和workflow.xml放在一起，但是分离出来的话可以方便分离。
   - lib 目录下面存放启动启动需要的库文件比如jar或者是so等。
然后我们需要将这写文件提交到hdfs上面，然后使用ozzie启动。ozzie会提供一个回调url，启动的任务应该会定时向这些url进行汇报状态（回调），或者是
ozzie去查询这写任务（这写任务应该也会内置httpserver）。

** java
   - 日志,log4j
   - 泛型 
   - 容器 
   - 多线程

