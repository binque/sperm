* spanner
  - link: http://research.google.com/archive/spanner.html
  - title: Spanner: Google's Globally-Distributed Database
  - date: 2012
  - misc:
    - Spanner——Google的全球化分布式数据库 - Sun Yongyue - 博客园 http://www.cnblogs.com/sunyongyue/archive/2012/09/20/spanner_note.html
    - Google Spanner原理- 全球级的分布式数据库_EMC中国研究院_新浪轻博客_Qing http://qing.weibo.com/2294942122/88ca09aa3300221n.html
    - Google Spanner (中文版) | 厦门大学数据库实验室 | 厦门大学 | 厦门大学计算机系|数据库实验室 http://dblab.xmu.edu.cn/node/230

** Abstract
  - Spanner is Google’s scalable, multi-version, globally-distributed, and synchronously-replicated database. It is the first system to distribute data at global scale and sup-port externally-consistent distributed transactions.  *(可扩展，多版本，全局分布式，同步复制的数据库系统，扩展性到全球级别，并且支持外部一致性的分布式事务）*
  - This paper describes how Spanner is structured, its feature set, the rationale underlying various design decisions, and a novel time API that exposes clock uncertainty. （主要分为两个方面，一个方面是组织结构以及关键特性还有各种设计上的权衡，另外一个就是支持时钟不确定性的时间API）
  - This API and its implementation are critical to supporting exter-nal consistency and a variety of powerful features: non-blocking reads in the past, lock-free read-only transac-tions, and atomic schema changes, across all of Spanner.（主要是使用这个API才能够保证外部一致性以及一些非常强大的功能，non-blocking read历史数据，lock-free read-only事务，以及原子schema变化）

** Introduction
   - At the high-est level of abstraction, it is a database that shards data across many sets of Paxos state machines in data- centers spread all over the world. Replication is used for global availability and geographic locality; clients auto-matically failover between replicas. （数据是进行shard的，每个shard实例之间的同步都是通过paxos状态机来完成的，实例可能散步于世界的各个地方。replication主要是为了提供全球可用性以及地理位置上的局部性，client能够自动地在replicas之间做failover切换）
   - Spanner automati-cally reshards data across machines as the amount of data or the number of servers changes, and it automatically migrates data across machines (even across datacenters) to balance load and in response to failures. （spanner对于data shard是自动完成的，当server数量变化的时候会reshard然后重新做balance)
   - Spanner is designed to scale up to millions of machines across hun-dreds of datacenters and trillions of database rows.(扩展到百万机器，上百个数据中心，10^12 rows）
   - Spanner’s main focus is managing cross-datacenter replicated data, but we have also spent a great deal of time in designing and implementing important database features on top of our distributed-systems infrastructure（虽然spanner主要focus是在跨机房的数据replication上，但是也花了相当多的时间来在分布式结构上设计和实现很多database特性，
     - Bigtable不能够支持复杂并且变化的schema，并且对于wide-area下面不能够很好地实现强一致性
     - Megastore可以解决Bigtable这个问题但是write throughput太差（使用MVCC方式造成的冲突）
     - Spanner has evolved from a Bigtable-like versioned key-value store into a temporal multi-version database. *TODO（dirlt）：什么叫做temporal?*
     - Data is stored in schematized semi-relational tables; 数据存放在schema化的半关系表里面 *NOTE（dirlt）：table是有schema的，但是table之间的关系并不像数据库table之间那么的具有关系性，可以认为是改良吧*
     - data is versioned, and each version is automati-cally timestamped with its commit time; old versions of data are subject to configurable garbage-collection poli-cies; and applications can read data at old timestamps.  （data都通过timestamp进行version，这样允许application读取历史数据，而old version数据能够被GC清除）
     - Spanner supports general-purpose transactions, and pro-vides a SQL-based query language.（支持ACID事务，上层提供查询语言）
   - As a globally-distributed database, Spanner provides several interesting features.（在扩展性和并发方面还提供了下面几个特性）
     - First, the replication con-figurations for data can be dynamically controlled at a fine grain by applications. （application能够精确控制data方式位置以及replication方式）
       - which datacenters contain which data
       - how far data is from its users (to control read latency)
       - how far replicas are from each other (to control write la-tency)
       - how many replicas are maintained (to con-trol durability, availability, and read performance).
     - Second, Spanner has two features that are difficult to implement in a distributed database: 
       - provides externally consistent reads and writes, （读写外部一致性）
       - and globally-consistent reads across the database at a time-stamp.（全局一致性地读取历史数据）
   - These features are enabled by the fact that Spanner as-signs globally-meaningful commit timestamps to trans-actions, even though transactions may be distributed. The timestamps reflect serialization order.（上面这些特性主要是因为spanner为事务提供了全局的提交时间戳，时间戳的顺序决定了串行顺序）
   - The key enabler of these properties is a new TrueTime API and its implementation. The API directly exposes clock uncertainty, and the guarantees on Spanner’s times-tamps depend on the bounds that the implementation pro- vides. （提供全局时间戳关键就是TrueTime API，API实现上暴露了时钟的不确定性，提供当前时钟的范围）
     - If the uncertainty is large, Spanner slows down to wait out that uncertainty. Google’s cluster-management software provides an implementation of the TrueTime API. 如果这个不确定性太大的话，那么spanner就需要slowdown等待这个uncertainty降下来
     - This implementation keeps uncertainty small (gen-erally less than 10ms) by using multiple modern clock references (GPS and atomic clocks). 通过GPS和原子钟来keep uncertainty small

** Implementation
   - A Spanner deployment is called a universe. Given that Spanner manages data globally, there will be only a handful of running universes. We currently run a test/playground universe, a development/production uni-
verse, and a production-only universe.（一个spanner实例称为universe）
   - Spanner is organized as a set of zones, where each zone is the rough analog of a deployment of Bigtable servers（spanner由多个zones组成，每个zone可以认为是一个bigtable servers的部署实例）
     - Zones are the unit of administrative deploy-ment. The set of zones is also the set of locations across which data can be replicated. （zone是用管理和部署的单元， *可以认为数据的每个replication在一个zone里面最多存在一份* ）
     - Zones can be added to or removed from a running system as new datacenters are brought into service and old ones are turned off, respec-tively. （zone能够自由地进入和从数据中心移除）
     - Zones are also the unit of physical isolation: there may be one or more zones in a datacenter, for example, if different applications’ data must be partitioned across different sets of servers in the same datacenter.（zone也是物理隔离的单元，可以在一个datacenter里面存在几个zone实例，这样在一个datacenter就可以存在同一个数据的replication多份）

--------------------

file:./images/spanner-server-organization.png

   - zonemaster 选择spanserver来serve data
   - spanserver serve data
   - location proxy 用来定位spanserver location *TODO（dirlt）：confuse with zonemaster*
   - universe master和plaecment driver都是单例
     - The universe master is primarily a console that displays status information about all the zones for inter-active debugging. （汇总信息）
     - The placement driver handles auto-mated movement of data across zones on the timescale of minutes. （在zone之间进行分钟级别自动balance）
     - The placement driver periodically commu-nicates with the spanservers to find data that needs to be moved, either to meet updated replication constraints or to balance load.（直接和spanserver通信）

*** Spanserver Software Stack
file:./images/spanserver-software-stack.png

   - At the bottom, each spanserver is responsible for between 100 and 1000 instances of a data structure called a tablet.(每个spanserver管理100-1000个tablet实例）
     - tablet和bigtable tablet概念非常类似，也是map数据结构并且value存储了多个版本 *这里的tablet是否为sorted-map?*
     - tablet’s state is stored in set of B-tree-like files and a write-ahead log, all on a distributed file system called Colossus (the successor to the Google File System) 状态保存在文件以及log上面存储在GFS2
   - To support replication, each spanserver implements a single Paxos state machine on top of each tablet. Each state machine stores its metadata and log in its corresponding tablet. （每个tablet上面实现paxos实例，状态机的实例将metadata以及operation log保存在管理的tablet里面）

*** Directories and Placement
*** Data Model
** TrueTime
** Concurrency Control
*NOTE(dirlt):并发控制是关键部分，但是这个部分我没有仔细阅读，主要是对paxos没有很好的理解*

** Evaluation
*** Microbenchmarks
*** Availability
*** TrueTime
*** F1

** Related Work
** Future Work
** Conclusions
