* megastore
#+OPTIONS: H:5
   - link: http://research.google.com/pubs/pub36971.html
   - title: Megastore: Providing Scalable, Highly Available Storage for Interactive Services
   - date: 2011

** ABSTRACT
   - Megastore is a storage system developed to meet the re-quirements of today’s interactive online services. Megas-tore blends the scalability of a NoSQL datastore with the convenience of a traditional RDBMS in a novel way, and provides both strong consistency guarantees and high avail-ability. （只要是为了满足现在交互式在线服务的存储需求，融合了NoSQL扩展性以及RDBMS的方便性，同时提供了强一致性以及高可用性）
   - We provide fully serializable ACID semantics within fine-grained partitions of data. This partitioning allows us to synchronously replicate each write across a wide area net-work with reasonable latency and support seamless failover between datacenters.（在一个数据区域上提供了完全的可串行化的ACID语义。在这个数据区域上面我们所有的写可以在WAN下面以非常小的延迟做同步replicate，同时支持datacenter之间的seamless failover）

** INTRODUCTION
   - We accomplish this by taking a middle ground in the RDBMS vs. NoSQL design space: we partition the data-store and replicate each partition separately, providing full ACID semantics within partitions, but only limited con-sistency guarantees across them. We provide traditional database features, such as secondary indexes, but only those features that can scale within user-tolerable latency limits, and only with the semantics that our partitioning scheme can support. 
     - 将数据进行partition，对于每个partition内部提供完全ACID语义的操作并且之间的replicate是强一致的，但是对于across partition仅仅是做到了有限的一致性（最终一致性？）
     - 同时提供了一些传统的db特性比如二级索引，但是这个feature可能会带来比较高的延迟，并且对应的语义是partition scheme（分区方案）所支持的（ *比如如果二级索引是跨partition的话，那么索引的更新是做不到原子的* ）
   - Contrary to conventional wisdom [24, 28], we were able to use Paxos to build a highly available system that pro-vides reasonable latencies for interactive applications while synchronously replicating writes across geographically dis-tributed datacenters. While many systems use Paxos solely for locking, master election, or replication of metadata and configurations, we believe that Megastore is the largest sys-tem deployed that uses Paxos to replicate primary user data across datacenters on every write.（mega使用paxos来完成低延迟下跨地域的同步复制来构建高可用性的系统。大部分的系统都是使用paxos来做locking，master选举或者是备份一些metadata或者是配置文件，而mega对每次写都用paxos做跨数据中心的复制）

*NOTE（dirlt）：table schema主要是用来描述各个表存储结构。mega使用上更类似NoSQL*

** TOWARD AVAILABILITY AND SCALE
   - To do so, we have taken a two-pronged approach:
     - for availability, we implemented a synchronous, fault-tolerant log replicator optimized for long distance-links;（对于availablity使用同步容错的log replicator，为了长距离链接进行了优化。 *使用优化的Paxos* ）
     - for scale, we partitioned data into a vast space of small databases, each with its own replicated log stored in a per-replica NoSQL datastore.（为了scale对于数据进行partition。各个partition有自己的replicated log，记录在自己所在的NoSQL datastore里面）

*** Replication
   - For cloud storage to meet availability demands, service providers must replicate data over a wide geographic area.（对于云存储必须满足可用性的需求，服务提供商必须跨地域进行replication），We evaluated common strategies for wide-area replication：（下面几个常见的跨地域replication解决方案）
     - Asynchronous Master/Slave 数据丢失风险，SPOF
     - Synchronous Master/Slave 延迟大，SPOF
     - Optimistic Replication 数据丢失风险并且不能够确定commit order，不能够做到ACID
   - We decided to use Paxos, a proven, optimal, fault-tolerant consensus algorithm with no requirement for a distinguished master. （paxos不需要单独的master）
     - We replicate a write-ahead log over a group of symmetric peers. Any node can initiate reads and writes. Each log append blocks on acknowledgments from a ma-jority of replicas, and replicas in the minority catch up as they are able—the algorithm’s inherent fault tolerance elim-inates the need for a distinguished “failed” state. （每个群组都有一个WAL，在群组里面所有的节点都可以发起read/write，只要大部分节点ack那么说明数据就写入了WAL返回成功，对于小部分没有ack的节点之后有办法跟上数据而不会造成不一致）
     - A novel extension to Paxos, detailed in Section 4.4.1, allows local reads at any up-to-date replica. Another extension permits single-roundtrip writes.（对于paxos进行了一些扩展，允许在任何一个up-to-date的节点上面进行local read，并且write只需要single-roundtrip）
     - *TODO（dirlt）：read paxos paper, then read this paper back*
   - Even with fault tolerance from Paxos, there are limita-tions to using a single log. With replicas spread over a wide area, communication latencies limit overall through-put. Moreover, progress is impeded when no replica is cur-rent or a majority fail to acknowledge writes. In a traditional SQL database hosting thousands or millions of users, us-ing a synchronously replicated log would risk interruptions of widespread impact . So to improve availability and throughput we use multiple replicated logs, each governing its own partition of the data set.（但是使用single log还是存在局限性。一方面因为跨地域进行replication那么延迟相当高 *我理解如果只有一个WAL的话，为了确保满足ACID性质那么所有的write必须是order的，这样所有的write都集中在一个WAL会导致latency非常高* ，另外更重要的因素是如果没有足够的replica使用或者是大部分节点都failed to ack write的话，那么所有的write都会被block住，整个progress就停止了。所以为了提高可用性以及吞吐我们必须使用multiple replicated logs，每个partition都有各自的replicated log）

*** Partitioning and Locality
   - To scale throughput and localize outages, we partition our data into a collection of entity groups, each indepen-dently and synchronously replicated over a wide area. The underlying data is stored in a scalable NoSQL datastore in each datacenter (see Figure 1) 划分的每个单元称为entity group. *后面简称EG*
     - Entities within an entity group are mutated with single-phase ACID transactions (for which the commit record is replicated via Paxos).（在一个EG里面操作满足ACID，操作使用paxos来进行同步复制）
     - Operations across entity groups could rely on expensive two-phase commits, but typically leverage Megastore’s efficient asynchronous messaging. （如果是跨EG的话那么需要使用两阶段提交，但是通过mega自带的异步消息队列完成）
     - A transac-tion in a sending entity group places one or more messages in a queue; transactions in receiving entity groups atomically consume those messages and apply ensuing mutations.（一个EG发起的事务可能会包含多个mutation，接收EG会atomically读取这些mutation然后apply them）

file:./images/megastore-scalable-replication.png

   - Indexes local to an entity group obey ACID semantics; those across entity groups have looser consistency. See Fig-ure 2 for the various operations on and between entity groups.（对于index也是一样，如果是local的话那么满足ACID语义，但是如果跨EG的话那么就只有更加松散一致性（ *可以认为是最终一致性？* ）

file:./images/megastore-operations-across-entity-groups.png

   - We use Google’s Bigtable for scalable fault-tolerant storage within a single datacenter, allowing us to support arbitrary read and write throughput by spreading operations across multiple rows.(底层使用bigtable来作为一个datacenter的存储）
   - We minimize latency and maximize throughput by let-ting applications control the placement of data: through the selection of Bigtable instances and specification of locality within an instance.（允许应用程序控制data placement来减小延迟和增大吞吐，包括选择bigtable的实例以及如何组织数据提高locality）
     - To minimize latency, applications try to keep data near users and replicas near each other. They assign each entity group to the region or continent from which it is accessed most. Within that region they assign a triplet or quintuplet of replicas to datacenters with isolated failure domains.（为了减少延迟将数据放在离user更近的位置）
     - For low latency, cache efficiency, and throughput, the data for an entity group are held in contiguous ranges of Bigtable rows. Our schema language lets applications control the placement of hierarchical data, storing data that is accessed together in nearby rows or denormalized into the same row.（schema language可以控制将一些有层级关系的数据进行连续存储或者是放在同一个row里面）

** A TOUR OF MEGASTORE
*** API Design Philosophy   
   - Normalized relational schemas rely on joins at query time to service user operations. This is not the right model for Megastore applications for several reasons:（不推荐在mega内部使用normalized relational schema这种方案）
     - High-volume interactive workloads benefit more from predictable performance than from an expressive query language.（大部分查询都是已知访问模式的）
     - Reads dominate writes in our target applications, so it pays to move work from read time to write time. *NOTE（dirlt）：so what？不理解为什么？*
     - Storing and querying hierarchical data is straightfor-ward in key-value stores like Bigtable. （Bigtable这种访问方式更加简单）
   - With this in mind, we designed a data model and schema language to offer fine-grained control over physical locality. Hierarchical layouts and declarative denormalization help eliminate the need for most joins. Queries specify scans or lookups against particular tables and indexes.（ *megastore可以帮助user来完成denormalization避免大部分的join，对于其他必须需要join的操作提供了二级索引以及一些辅助的算法* *NOTE（dirlt）：这个应该就是megastore在data model上面做的主要工作* ）

*** Data Model
file:./images/megastore-sample-schema.png

   - As in an RDBMS, the data model is de-clared in a schema and is strongly typed. Each schema has a set of tables, each containing a set of entities, which in turn contain a set of properties. Properties are named and typed values. The types can be strings, various flavors of numbers, or Google’s Protocol Buffers. They can be re-quired, optional, or repeated (allowing a list of values in a single property). All entities in a table have the same set of allowable properties. A sequence of properties is used to form the primary key of the entity, and the primary keys must be unique within the table. Figure 3 shows an example schema for a simple photo storage application. （datamodel和RDBMS非常类似，schema也是由很多table来组成，每个table包含很多entity，而每个entity包含很多property。对于property有类型包括字符串，整数以及protobuf本身，并且本身可以是required，optional以及repeated的。多个property组成primary key，而primary key的内容也是由这些property value组合起来的。比如上面就是(user_id, photo_id) ）
   - Megastore tables are either entity group root tables or child tables. Each child table must declare a single distin-guished foreign key referencing a root table, illustrated by the ENTITY GROUP KEY annotation in Figure 3. Thus each child entity references a particular entity in its root table (called the root entity). An entity group consists of a root entity along with all entities in child tables that reference it. A Megastore instance can have several root tables, resulting in different classes of entity groups.（tables分为root table和child table，root table存在PRIMARY KEY，而child table必须使用一个foreign key来引用root table。这样对于每一个root table entry来说，可能会存在很多child entry来引用它）

**** Pre-Joining with Keys
   - Each entity is mapped into a single Bigtable row; the primary key values are concatenated to form the Bigtable row key, and each remaining property occupies its own Bigtable column.（每一个entity占据了bigtable的一行，rowkey使用primary key拼接而成，而剩余的property则对应到bigtable的column）
   - The IN TABLE User direc-tive instructs Megastore to colocate these two tables into the same Bigtable, and the key ordering ensures that Photo entities are stored adjacent to the corresponding User. This mechanism can be applied recursively to speed queries along arbitrary join depths. Thus, users can force hierarchical lay-out by manipulating the key order. （IN TABLE可以用来将child table entry紧跟在对应的root table entry之后， *NOTE（dirlt）：原因我倒是没有看明白，但是这样至少对于相关的数据存储访问是非常有利的* ）
   - Schemas declare keys to be sorted ascending or descend-ing, or to avert sorting altogether: the SCATTER attribute in-structs Megastore to prepend a two-byte hash to each key. Encoding monotonically increasing keys this way prevents hotspots in large data sets that span Bigtable servers.（schema可以用来表示是否按照key来进行排序，或者是进行scatter，所谓scatter就是不要放key过于集中地存放，可以通过在key前面添加2个字节的hashcode来打散）

**** Indexes

**** Mapping to Bigtable

*** Transactions and Concurrency Control
**** Queues
**** Two-Phase Commit
*** Other Features

** REPLICATION


** EXPERIENCE


** RELATED WORK
   - Recently, there has been increasing interest in NoSQL data storage systems to meet the demand of large web ap-plications. Representative work includes Bigtable, Cas-sandra, and Yahoo PNUTS. In these systems, scal-ability is achieved by sacrificing one or more properties of traditional RDBMS systems, e.g., transactions, schema sup-port, query capability. 都通过牺牲一些传统的RDBMS的特性来达到扩展性比如事务，schema，以及query能力（复杂的SQL查询以及运算等） These systems often reduce the scope of transactions to the granularity of single key access and thus place a significant hurdle to building appli-cations （事务粒度仅仅是到了row级别，这样为应用程序造成了一定的负担）Some systems extend the scope of transac-tions to multiple rows within a single table, for example the Amazon SimpleDB uses the concept of domain as the transactional unit. （而另外一些系统级别则放宽到了多列比如Amazon SimpleDB使用domain来作为事务单元） Yet such efforts are still limited because transactions cannot cross tables or scale arbitrarily.（但是依然不能够跨表来完成事务） More-over, most current scalable data storage systems lack the rich data model of an RDBMS, which increases the burden on developers. （更重要的是缺乏丰富的data model以及query能力给开发人员造成的负担）
   - Data replication across geographically distributed data-centers is an indispensable means of improving availability in state-of-the-art storage systems. （使用跨地域地方来进行data replication是必要的手段） Most prevailing data storage systems use asynchronous replication schemes with a weaker consistency model. For example, Cassandra, HBase, CouchDB, and Dynamo use an eventual consistency model and PNUTS uses “timeline” consistency （使用timeline一致性 *TODO（dirlt）：？？？* ） Until recently, few have used Paxos to achieve synchronous replication. SCALARIS is one example that uses the Paxos commit protocol to implement replication for a distrib-uted hash table. Keyspace also uses Paxos to imple-ment replication on a generic key-value store.（这几个系统都使用paxos实现了数据上的replication)

** CONCLUSION
